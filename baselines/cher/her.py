
# import numpy as np
# import random
# import baselines.cher.config_curriculum as config_cur
# import math
# from sklearn.neighbors import NearestNeighbors
# from gym.envs.robotics import rotations
#
#
# def make_sample_her_transitions(replay_strategy, replay_k, reward_fun):
#     """Creates a sample function that can be used for HER experience replay.
#
#     Args:
#         replay_strategy (in ['future', 'none']): the HER replay strategy; if set to 'none',
#             regular DDPG experience replay is used
#         replay_k (int): the ratio between HER replays and regular replays (e.g. k = 4 -> 4 times
#             as many HER replays as regular replays are used)
#         reward_fun (function): function to re-compute the reward with substituted goals
#     """
#     if replay_strategy == 'future':
#         future_p = 1 - (1. / (1 + replay_k))
#     else:  # 'replay_strategy' == 'none'
#         future_p = 0
#
#     def curriculum(transitions, batch_size_in_transitions, batch_size):
#         sel_list = lazier_and_goals_sample_kg(
#             transitions['g'], transitions['ag'], transitions['o'],
#             batch_size_in_transitions)
#         transitions = {
#             key: transitions[key][sel_list].copy()
#             for key in transitions.keys()
#         }
#         config_cur.learning_step += 1
#         return transitions
#
#     def fa(k, a_set, v_set, sim, row, col):
#         if len(a_set) == 0:
#             init_a_set = []
#             marginal_v = 0
#             for i in v_set:
#                 max_ki = 0
#                 if k == col[i]:
#                     max_ki = sim[i]
#                 init_a_set.append(max_ki)
#                 marginal_v += max_ki
#             return marginal_v, init_a_set
#
#         new_a_set = []
#         marginal_v = 0
#         for i in v_set:
#             sim_ik = 0
#             if k == col[i]:
#                 sim_ik = sim[i]
#
#             if sim_ik > a_set[i]:
#                 max_ki = sim_ik
#                 new_a_set.append(max_ki)
#                 marginal_v += max_ki - a_set[i]
#             else:
#                 new_a_set.append(a_set[i])
#         return marginal_v, new_a_set
#
#     def lazier_and_goals_sample_kg(goals, ac_goals, obs,
#                                    batch_size_in_transitions):
#         if config_cur.goal_type == "ROTATION":
#             goals, ac_goals = goals[..., 3:], ac_goals[..., 3:]
#
#         num_neighbor = 1
#         kgraph = NearestNeighbors(
#             n_neighbors=num_neighbor, algorithm='kd_tree',
#             metric='euclidean').fit(goals).kneighbors_graph(
#                 mode='distance').tocoo(copy=False)
#         row = kgraph.row
#         col = kgraph.col
#         sim = np.exp(
#             -np.divide(np.power(kgraph.data, 2),
#                        np.mean(kgraph.data)**2))
#         delta = np.mean(kgraph.data)
#
#         sel_idx_set = []
#         idx_set = [i for i in range(len(goals))]
#         balance = config_cur.fixed_lambda
#         if int(balance) == -1:
#             balance = math.pow(                     # æ¼”ç®—æ³•ç•¶ä¸­æ¢é…æ¢ç´¢æ¯”ä¾‹ä½¿ç”¨çš„
#                 1 + config_cur.learning_rate,
#                 config_cur.learning_step) * config_cur.lambda_starter
#         v_set = [i for i in range(len(goals))]
#         max_set = []
#         for i in range(0, batch_size_in_transitions):
#             sub_size = 3
#             sub_set = random.sample(idx_set, sub_size)
#             sel_idx = -1
#             max_marginal = float("-inf")  #-1 may have an issue
#             for j in range(sub_size):
#                 k_idx = sub_set[j]
#                 marginal_v, new_a_set = fa(k_idx, max_set, v_set, sim, row,
#                                            col)
#                 euc = np.linalg.norm(goals[sub_set[j]] - ac_goals[sub_set[j]])
#                 marginal_v = marginal_v - balance * euc
#                 if marginal_v > max_marginal:
#                     sel_idx = k_idx
#                     max_marginal = marginal_v
#                     max_set = new_a_set
#
#             idx_set.remove(sel_idx)
#             sel_idx_set.append(sel_idx)
#         return np.array(sel_idx_set)
#
#     # does not use it: from gym https://github.com/openai/gym/blob/master/gym/envs/robotics/hand/manipulate.py#L87
#     def _goal_rot_distance(goal_a, goal_b):
#         assert goal_a.shape == goal_b.shape
#         assert goal_a.shape[-1] == 7
#         d_rot = np.zeros_like(goal_b[..., 0])
#         quat_a, quat_b = goal_a[..., 3:], goal_b[..., 3:]
#         # Subtract quaternions and extract angle between them.
#         quat_diff = rotations.quat_mul(quat_a,
#                                        rotations.quat_conjugate(quat_b))
#         angle_diff = 2 * np.arccos(np.clip(quat_diff[..., 0], -1., 1.))
#         d_rot = angle_diff
#         return d_rot
#
#     # does not use it
#     def lazier_and_goals_sample(goals, ac_goals, obs,
#                                 batch_size_in_transitions):
#         init = []
#         init.append(goals[0])
#         sel_idx_set = set([0])
#         idx_set = [i for i in range(len(goals))]
#         idx_set.remove(0)
#         balance = 1.0
#         #balance = config_cur.learning_down + config_cur.learning_rate * config_cur.learning_step / config_cur.total_learning_step
#         #balance = math.pow(1 + config_cur.learning_rate, config_cur.learning_step)*config_cur.lambda_starter
#         balance = math.pow(1 + config_cur.learning_rate,
#                            config_cur.learning_step)
#         for i in range(1, batch_size_in_transitions):
#             max_dist = np.NINF  #-100.
#             sel_idx = -1
#             sub_size = 3
#             sub_set = random.sample(idx_set, sub_size)
#             for j in range(sub_size):
#                 ob = obs[sub_set[j]]
#                 gripper_pos = ob[0:3]
#                 object_pos = ob[3:6]
#                 dist = get_distance(goals[sub_set[j]], init)
#                 comb_dist = dist / len(init) - balance * np.linalg.norm(
#                     goals[sub_set[j]] - ac_goals[sub_set[j]]
#                 ) - balance * np.linalg.norm(gripper_pos - object_pos)
#                 #comb_dist = -balance * np.linalg.norm(goals[sub_set[j]]-ac_goals[sub_set[j]])
#                 if comb_dist > max_dist:
#                     max_dist = comb_dist
#                     sel_idx = sub_set[j]
#             init.append(goals[sel_idx])
#             idx_set.remove(sel_idx)
#             sel_idx_set.add(sel_idx)
#         return np.array(list(sel_idx_set))
#
#     # does not use it
#     def get_distance(p, init_set):
#         dist = 0.
#         for i in range(len(init_set)):
#             dist += np.linalg.norm(p - init_set[i])
#         return dist
#
#     def _sample_her_transitions(episode_batch, batch_size_in_transitions):
#         """episode_batch is {key: array(buffer_size x T x dim_key)}     #2,50,4
#         """
#         T = episode_batch['u'].shape[1]     # 2,50,4
#         rollout_batch_size = episode_batch['u'].shape[0]
#         batch_size = config_cur.learning_candidates #128
#
#         # Select which episodes and time steps to use.
#         episode_idxs = np.random.randint(0, rollout_batch_size, batch_size) #128
#         t_samples = np.random.randint(T, size=batch_size)   #128
#         transitions = { #u,info_is_success,o_2,ag,g,o,ag_2
#             key: episode_batch[key][episode_idxs, t_samples].copy()
#             for key in episode_batch.keys()
#         }
#
#         # Select future time indexes proportional with probability future_p. These
#         # will be used for HER replay by substituting in future goals.
#         her_indexes = np.where(np.random.uniform(size=batch_size) < future_p)
#         future_offset = np.random.uniform(size=batch_size) * (T - t_samples)
#         future_offset = future_offset.astype(int)
#         future_t = (t_samples + 1 + future_offset)[her_indexes]
#
#         # Replace goal with achieved goal but only for the previously-selected
#         # HER transitions (as defined by her_indexes). For the other transitions,
#         # keep the original goal.
#         future_ag = episode_batch['ag'][episode_idxs[her_indexes], future_t]
#         transitions['g'][her_indexes] = future_ag
#
#         #assert batch_size_in_transitions == 64
#         if batch_size_in_transitions != config_cur.learning_selected:
#             batch_size_in_transitions = config_cur.learning_selected
#
#         # curriculum learning process
#         transitions = curriculum(transitions, batch_size_in_transitions,
#                                  batch_size)
#         batch_size = batch_size_in_transitions
#
#         # Reconstruct info dictionary for reward  computation.
#         info = {}
#         for key, value in transitions.items():
#             if key.startswith('info_'):
#                 info[key.replace('info_', '')] = value
#
#         # Re-compute reward since we may have substituted the goal.
#         reward_params = {k: transitions[k] for k in ['ag_2', 'g']}
#         reward_params['info'] = info
#         transitions['r'] = reward_fun(**reward_params)
#
#         transitions = {
#             k: transitions[k].reshape(batch_size, *transitions[k].shape[1:])
#             for k in transitions.keys()
#         }
#
#         assert (transitions['u'].shape[0] == batch_size_in_transitions)
#
#         return transitions
#
#     return _sample_her_transitions

import numpy as np
import random
import baselines.cher.config_curriculum as config_cur
import math
from sklearn.neighbors import NearestNeighbors
from gym.envs.robotics import rotations
def make_sample_her_transitions(replay_strategy, replay_k, reward_fun):
    # é€™é‚Šæ‡‰è©²æ˜¯proximityæ¯”ä¾‹çš„éƒ¨ä»½
    if replay_strategy == 'future':
        future_p = 1 - (1. / (1 + replay_k))
    else:
        future_p = 0

    def _sample_her_transitions(episode_batch, batch_size_in_transitions):

        # ä¸€æ‰¹50å€‹ï¼Œæ‰¹æ¬¡çš„å…§å®¹ï¼škey: array(buffer_size x T x dim_key)
        #                           2      x50 x    4
        T = episode_batch['u'].shape[1]
        rollout_batch_size = episode_batch['u'].shape[0]
        batch_size = config_cur.learning_candidates

        episode_idxs = np.random.randint(0, rollout_batch_size, batch_size)
        t_samples = np.random.randint(T, size=batch_size)
        transitions = {key: episode_batch[key][episode_idxs, t_samples].copy()
                       for key in episode_batch.keys()}

        her_indexes = np.where(np.random.uniform(size=batch_size) < future_p)  # éš¨æ©Ÿå–proximityæ¯”ä¾‹çš„æ•¸é‡
        future_offset = np.random.uniform(size=batch_size) * (T - t_samples)
        future_offset = future_offset.astype(int)
        future_t = (t_samples + 1 + future_offset)[her_indexes]

        future_ag = episode_batch['ag'][episode_idxs[her_indexes], future_t]  # ä¸‹ä¸€æ¬¡å·²å®Œæˆç›®æ¨™ï¼Œepisodeè£¡é¢çš„æŸæ¬¡
        transitions['g'][her_indexes] = future_ag

        if batch_size_in_transitions != config_cur.learning_selected:  # ä¿éšª
            batch_size_in_transitions = config_cur.learning_selected
        transitions = curriculum(transitions, batch_size_in_transitions, batch_size)  # æ ¹æ“šç•¶ä¸‹çš„å­¸ç¿’éšæ®µå»èª¿æ•´
        batch_size = batch_size_in_transitions
        '''call curriculum function'''
        info = {}
        for key, value in transitions.items():
            if key.startswith('info_'):
                info[key.replace('info_', '')] = value

        # ç”¨transitionså–å¾—reward
        reward_params = {k: transitions[k] for k in ['ag_2', 'g']}
        reward_params['info'] = info
        transitions['r'] = reward_fun(**reward_params)  # ä½¿ç”¨configä¸­çš„å®šç¾©è¨ˆç®—reward
        transitions = {
            k: transitions[k].reshape(batch_size, *transitions[k].shape[1:])
            for k in transitions.keys()
        }
        assert (transitions['u'].shape[0] == batch_size_in_transitions)
        return transitions

    def curriculum(transitions, batch_size_in_transitions, batch_size):
        sel_list = lazier_and_goals_sample_kg(transitions['g'], transitions['ag'], transitions['o'],
                                              batch_size_in_transitions)
        transitions = {key: transitions[key][sel_list].copy()
                       for key in transitions.keys()}
        config_cur.learning_step += 1  # ç”¨ä¾†ç´€éŒ„ç¾åœ¨åˆ°è¨“ç·´çš„å“ªè£¡äº†
        return transitions

    def lazier_and_goals_sample_kg(goals, ac_goals, obs, batch_size_in_transitions):  # Algorithm 1 -- Stochastic Greedy
        # â¬‡ çœ‹èµ·ä¾†æ²’æœ‰ç”¨çš„è½‰ç½®ç›®æ¨™åˆ¤æ–· â¬‡
        # if config_cur.goal_type =="ROTATION":
        #     goals,ac_goals=goals[...,3:],ac_goals[...,3:]

        # 128çµ„ä¸‰ç¶­è³‡æ–™ä¸‹å»åšç›¸é—œæ€§çš„åˆ†ç¾¤
        # NearsetNeighborä½¿ç”¨ï¼šæ‰¾é™„è¿‘1å€‹neighbor
        # ç®—æ³•ä½¿ç”¨ï¼škd tree
        # è¨ˆç®—è·é›¢æ–¹å¼ï¼šeuclidean
        num_neighbor = 1
        kgraph = NearestNeighbors(n_neighbors=num_neighbor, algorithm='kd_tree', metric='euclidean').fit(
            goals).kneighbors_graph(mode=
                                    'distance').tocoo(copy=False)
        row = kgraph.row  # row æ•°ç»„åŒ…å«"èµ·å§‹"èŠ‚ç‚¹çš„ç´¢å¼•
        col = kgraph.col  # col æ•°ç»„åŒ…å«"ç›®æ ‡"èŠ‚ç‚¹çš„ç´¢å¼•
        sim = np.exp(-np.divide(np.power(kgraph.data, 2), np.mean(kgraph.data) ** 2))
        # å› ç‚ºnum_neighboræ•¸=1ï¼Œæ‰€ä»¥simå°±æ˜¯æœ€è¿‘çš„1å€‹neighborè·é›¢è½‰æ›çš„ç›¸ä¼¼åˆ†æ•¸
        delta = np.mean(kgraph.data)

        sel_idx_set = []  # ç­‰å¾…é¸æ“‡çš„è³‡æ–™å †
        idx_set = [i for i in range(len(goals))]  # idx
        balance = config_cur.fixed_lambda  # èª¿é…çš„æ¯”ä¾‹ï¼Œå¾configå–å¾—ï¼Œ-1
        if int(balance) == -1:
            balance = math.pow(1 + config_cur.learning_rate,
                               config_cur.learning_step) * config_cur.lambda_starter  # ((1+0.0001)^step)*1
            v_set = [i for i in range(len(goals))]
            max_set = []
            for i in range(0, batch_size_in_transitions):  # 0~64
                sub_size = 3
                sub_set = random.sample(idx_set, sub_size)  # 0~128éš¨æ©Ÿé¸3
                sel_idx = -1
                max_marginal = float("-inf")
                for j in range(sub_size):  # åŸ·è¡Œä¸‰æ¬¡
                    k_idx = sub_set[j]  # ç¬¬1/2/3å€‹
                    marginal_v, new_a_set = fa(k_idx, max_set, v_set, sim, row, col)# marginal_V = ğ¹_ğ‘‘ğ‘–ğ‘£(å¤šæ¨£æ€§ï¼‰
                    euc = np.linalg.norm(goals[sub_set[j]] - ac_goals[sub_set[j]])  # å…©å€‹é»çš„æ­æ°è·é›¢
                    marginal_v = marginal_v - balance * euc # marginal_v = F(ğ‘–â”‚ğ´)
                    if marginal_v > max_marginal:  # æ¯”è¼ƒä¸‰æ¬¡å–å‡ºæœ€å¤§çš„
                        sel_idx = k_idx
                        max_marginal = marginal_v
                        max_set = new_a_set

                idx_set.remove(sel_idx)
                sel_idx_set.append(sel_idx)
            return np.array(sel_idx_set)

    def fa(k, a_set, v_set, sim, row, col):
        if len(a_set) == 0:  # ä¸€é–‹å§‹è¼¸å…¥æ˜¯ç©ºé›†åˆï¼Œä¹Ÿå°±æ˜¯åŸ·è¡Œç¬¬ä¸€æ¬¡sub_sizeçš„æ™‚å€™
            init_a_set = []
            marginal_v = 0
            for i in v_set:  # çœ‹éæ‰€æœ‰128æ¯”è³‡æ–™
                max_ki = 0
                if k == col[i]:  # å¦‚æœéš¨æ“ å‡ºä¾†çš„3å€‹ç­‰æ–¼å…¶ä»–äººçš„NearsNeighborçš„è©±
                    max_ki = sim[i]  # è¨ˆç®—æ‹¿å‡ºé‚£ä¸€å€‹äººçš„simåˆ†æ•¸
                init_a_set.append(max_ki)  # 0,0,0,...,0,sim[i],sim[i],...
                marginal_v += max_ki  # ç¸½å’Œ
            return marginal_v, init_a_set
        # åœ¨åŸ·è¡Œç¬¬2/3æ¬¡
        new_a_set = []
        marginal_v = 0
        for i in v_set:  # çœ‹éæ‰€æœ‰128æ¯”è³‡æ–™
            sim_ik = 0
            if k == col[i]:  # å¦‚æœéš¨æ“ å‡ºä¾†çš„3å€‹ç­‰æ–¼å…¶ä»–äººçš„NearsNeighborçš„è©±
                sim_ik = sim[i]  # è¨ˆç®—æ‹¿å‡ºé‚£ä¸€å€‹äººçš„simåˆ†æ•¸

            # a_setæ‡‰è©²æ˜¯å‰é¢æ¬¡ä¸­çš„æœ€å¤§å€¼ï¼Œå¦‚æœæ¯”è¼ƒå¤§
            if sim_ik > a_set[i]:
                max_ki = sim_ik  # å¦‚æœæ¯”è¼ƒå¤§ï¼Œæ›¿æ›
                new_a_set.append(max_ki)
                marginal_v += max_ki - a_set[i]  # åŠ ä¸Šï¼šæœ€å¤§çš„æ¸›æ‰æ¬¡å¤§çš„
            # å¦‚æœç•¶ä¸‹çš„æ²’æœ‰æ¯”è¼ƒå¤§
            else:
                new_a_set.append(a_set[i])
        return marginal_v, new_a_set


    return _sample_her_transitions


'''
    def plot_kgraph(kgraph,row,col):
        # ä½¿ç”¨æ–¹æ³•
        # plot_kgraph(kgraph, row, col)

        import networkx as nx
        import matplotlib.pyplot as plt
        import numpy as np

        # åˆ›å»ºä¸€ä¸ªç©ºçš„æœ‰å‘å›¾
        graph = nx.DiGraph()

        # æ·»åŠ è¾¹åˆ°å›¾ä¸­
        for i in range(len(row)):
            weight = kgraph.data[i]
            if weight == 0:
                edge_color = 'gray'  # å°†è¾¹çš„é¢œè‰²è®¾ç½®ä¸ºç°è‰²
            else:
                edge_color = 'black'  # é»˜è®¤è¾¹çš„é¢œè‰²ä¸ºé»‘è‰²
            graph.add_edge(row[i], col[i], weight=weight, color=edge_color)

        # è®¾ç½®å›¾å½¢çš„å¤§å°
        plt.figure(figsize=(10, 6))

        # ç»˜åˆ¶å›¾å½¢
        pos = nx.spring_layout(graph)  # é€‰æ‹©èŠ‚ç‚¹å¸ƒå±€ç®—æ³•

        # ç»˜åˆ¶èŠ‚ç‚¹
        nx.draw_networkx_nodes(graph, pos)

        # ç»˜åˆ¶è¾¹ï¼Œå¹¶è®¾ç½®è¾¹çš„é¢œè‰²
        edge_colors = [graph[u][v]['color'] for u, v in graph.edges()]
        nx.draw_networkx_edges(graph, pos, edge_color=edge_colors)

        # ç»˜åˆ¶èŠ‚ç‚¹çš„æ ‡ç­¾
        node_labels = {node: str(node) for node in graph.nodes()}
        nx.draw_networkx_labels(graph, pos, labels=node_labels)

        # # ç»˜åˆ¶è¾¹çš„æƒé‡æ ‡ç­¾
        # edge_labels = nx.get_edge_attributes(graph, 'weight')
        # nx.draw_networkx_edge_labels(graph, pos, edge_labels=edge_labels)

        # è°ƒæ•´å›¾å½¢å¸ƒå±€ï¼Œä»¥ä¾¿æ ‡ç­¾ä¸é‡å 
        plt.tight_layout()

        # æ˜¾ç¤ºå›¾å½¢
        plt.axis('off')

        plt.savefig('/home/jeff/CHER/baselines/cher/experiment/filename.png', dpi=300)

    def plot_kgraph_pca(kgraph, goals):
        import networkx as nx
        import matplotlib.pyplot as plt
        from sklearn.decomposition import PCA

        # ä½¿ç”¨ PCA é™ç¶­
        pca = PCA(n_components=2)
        goals_2d = pca.fit_transform(goals)

        # åˆ›å»ºä¸€ä¸ªç©ºçš„æœ‰å‘å›¾
        graph = nx.DiGraph()

        # æ·»åŠ è¾¹åˆ°å›¾ä¸­
        for i, j, v in zip(kgraph.row, kgraph.col, kgraph.data):
            if v == 0:
                edge_color = 'gray'  # å°†è¾¹çš„é¢œè‰²è®¾ç½®ä¸ºç°è‰²
            else:
                edge_color = 'black'  # é»˜è®¤è¾¹çš„é¢œè‰²ä¸ºé»‘è‰²
            graph.add_edge(i, j, weight=v, color=edge_color)

        # è®¾ç½®å›¾å½¢çš„å¤§å°
        plt.figure(figsize=(10, 6))

        # é€‰æ‹©èŠ‚ç‚¹å¸ƒå±€ç®—æ³•ï¼Œä½¿ç”¨ PCA é™ç»´åçš„åæ ‡
        pos = {i: goals_2d[i] for i in range(len(goals_2d))}

        # ç»˜åˆ¶èŠ‚ç‚¹
        nx.draw_networkx_nodes(graph, pos)

        # ç»˜åˆ¶è¾¹ï¼Œå¹¶è®¾ç½®è¾¹çš„é¢œè‰²
        edge_colors = [graph[u][v]['color'] for u, v in graph.edges()]
        nx.draw_networkx_edges(graph, pos, edge_color=edge_colors)

        # ç»˜åˆ¶èŠ‚ç‚¹çš„æ ‡ç­¾
        node_labels = {node: str(node) for node in graph.nodes()}
        nx.draw_networkx_labels(graph, pos, labels=node_labels)

        # è°ƒæ•´å›¾å½¢å¸ƒå±€ï¼Œä»¥ä¾¿æ ‡ç­¾ä¸é‡å 
        plt.tight_layout()

        # æ˜¾ç¤ºå›¾å½¢
        plt.axis('off')

        # å°†å›¾åƒä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
        plt.savefig('/home/jeff/CHER/baselines/cher/experiment/filename.png', dpi=300)
'''
