Logging to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0
T: 50
_Q_lr: 0.001
_action_l2: 1.0
_batch_size: 64
_buffer_size: 100000
_clip_obs: 200.0
_hidden: 256
_layers: 3
_max_u: 1.0
_network_class: baselines.her.actor_critic:ActorCritic
_norm_clip: 5
_norm_eps: 0.01
_pi_lr: 0.001
_polyak: 0.95
_relative_goals: False
_scope: ddpg
ddpg_params: {'scope': 'ddpg', 'network_class': 'baselines.her.actor_critic:ActorCritic', 'max_u': 1.0, 'action_l2': 1.0, 'pi_lr': 0.001, 'norm_eps': 0.01, 'polyak': 0.95, 'layers': 3, 'buffer_size': 100000, 'Q_lr': 0.001, 'batch_size': 64, 'norm_clip': 5, 'hidden': 256, 'clip_obs': 200.0, 'relative_goals': False}
env_name: HandReach-v0
gamma: 0.98
make_env: <function prepare_params.<locals>.make_env at 0x7f72c52a6488>
n_batches: 40
n_cycles: 50
n_test_rollouts: 10
noise_eps: 0.2
random_eps: 0.3
replay_k: 4
replay_strategy: future
rollout_batch_size: 2
test_with_polyak: False
Creating a DDPG agent with action space 20 x 1.0...
Training...
------------------------------------
| epoch              | 0           |
| stats_g/mean       | 0.67421025  |
| stats_g/std        | 0.019273039 |
| stats_o/mean       | 0.31632054  |
| stats_o/std        | 0.70160234  |
| test/episode       | 20.0        |
| test/mean_Q        | -2.779821   |
| test/success_rate  | 0.0         |
| train/episode      | 100.0       |
| train/success_rate | 0.0         |
------------------------------------
New best success rate: 0.0. Saving policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_best.pkl ...
Saving periodic policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_0.pkl ...
------------------------------------
| epoch              | 1           |
| stats_g/mean       | 0.67376995  |
| stats_g/std        | 0.018492403 |
| stats_o/mean       | 0.30499753  |
| stats_o/std        | 0.73424864  |
| test/episode       | 40.0        |
| test/mean_Q        | -1.9715096  |
| test/success_rate  | 0.0         |
| train/episode      | 200.0       |
| train/success_rate | 0.0         |
------------------------------------
New best success rate: 0.0. Saving policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_best.pkl ...
------------------------------------
| epoch              | 2           |
| stats_g/mean       | 0.6735179   |
| stats_g/std        | 0.018492935 |
| stats_o/mean       | 0.29827884  |
| stats_o/std        | 0.7752922   |
| test/episode       | 60.0        |
| test/mean_Q        | -2.1937888  |
| test/success_rate  | 0.0         |
| train/episode      | 300.0       |
| train/success_rate | 0.0         |
------------------------------------
New best success rate: 0.0. Saving policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_best.pkl ...
------------------------------------
| epoch              | 3           |
| stats_g/mean       | 0.6737805   |
| stats_g/std        | 0.018370258 |
| stats_o/mean       | 0.29928696  |
| stats_o/std        | 0.79334825  |
| test/episode       | 80.0        |
| test/mean_Q        | -2.4704738  |
| test/success_rate  | 0.0         |
| train/episode      | 400.0       |
| train/success_rate | 0.0         |
------------------------------------
New best success rate: 0.0. Saving policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_best.pkl ...
------------------------------------
| epoch              | 4           |
| stats_g/mean       | 0.67389286  |
| stats_g/std        | 0.018310118 |
| stats_o/mean       | 0.30016884  |
| stats_o/std        | 0.8065663   |
| test/episode       | 100.0       |
| test/mean_Q        | -2.7547126  |
| test/success_rate  | 0.1         |
| train/episode      | 500.0       |
| train/success_rate | 0.0         |
------------------------------------
New best success rate: 0.1. Saving policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_best.pkl ...
------------------------------------
| epoch              | 5           |
| stats_g/mean       | 0.6739778   |
| stats_g/std        | 0.018293984 |
| stats_o/mean       | 0.2995115   |
| stats_o/std        | 0.81429666  |
| test/episode       | 120.0       |
| test/mean_Q        | -2.6263137  |
| test/success_rate  | 0.1         |
| train/episode      | 600.0       |
| train/success_rate | 0.0         |
------------------------------------
New best success rate: 0.1. Saving policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_best.pkl ...
Saving periodic policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_5.pkl ...
------------------------------------
| epoch              | 6           |
| stats_g/mean       | 0.674357    |
| stats_g/std        | 0.018680848 |
| stats_o/mean       | 0.30127233  |
| stats_o/std        | 0.8186209   |
| test/episode       | 140.0       |
| test/mean_Q        | -2.371219   |
| test/success_rate  | 0.1         |
| train/episode      | 700.0       |
| train/success_rate | 0.0         |
------------------------------------
New best success rate: 0.1. Saving policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_best.pkl ...
------------------------------------
| epoch              | 7           |
| stats_g/mean       | 0.6737409   |
| stats_g/std        | 0.019126454 |
| stats_o/mean       | 0.3023595   |
| stats_o/std        | 0.8230284   |
| test/episode       | 160.0       |
| test/mean_Q        | -3.2733464  |
| test/success_rate  | 0.0         |
| train/episode      | 800.0       |
| train/success_rate | 0.0         |
------------------------------------
-----------------------------------
| epoch              | 8          |
| stats_g/mean       | 0.6737524  |
| stats_g/std        | 0.01912133 |
| stats_o/mean       | 0.3026745  |
| stats_o/std        | 0.82501274 |
| test/episode       | 180.0      |
| test/mean_Q        | -4.097689  |
| test/success_rate  | 0.0        |
| train/episode      | 900.0      |
| train/success_rate | 0.0        |
-----------------------------------
------------------------------------
| epoch              | 9           |
| stats_g/mean       | 0.6734919   |
| stats_g/std        | 0.019289017 |
| stats_o/mean       | 0.30239722  |
| stats_o/std        | 0.8244799   |
| test/episode       | 200.0       |
| test/mean_Q        | -4.0243287  |
| test/success_rate  | 0.05        |
| train/episode      | 1000.0      |
| train/success_rate | 0.0         |
------------------------------------
-----------------------------------
| epoch              | 10         |
| stats_g/mean       | 0.673385   |
| stats_g/std        | 0.01925016 |
| stats_o/mean       | 0.30146965 |
| stats_o/std        | 0.8265299  |
| test/episode       | 220.0      |
| test/mean_Q        | -2.9321852 |
| test/success_rate  | 0.0        |
| train/episode      | 1100.0     |
| train/success_rate | 0.0        |
-----------------------------------
Saving periodic policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_10.pkl ...
------------------------------------
| epoch              | 11          |
| stats_g/mean       | 0.67326516  |
| stats_g/std        | 0.019099465 |
| stats_o/mean       | 0.300913    |
| stats_o/std        | 0.827377    |
| test/episode       | 240.0       |
| test/mean_Q        | -2.139405   |
| test/success_rate  | 0.15        |
| train/episode      | 1200.0      |
| train/success_rate | 0.01        |
------------------------------------
New best success rate: 0.15. Saving policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_best.pkl ...
------------------------------------
| epoch              | 12          |
| stats_g/mean       | 0.6731936   |
| stats_g/std        | 0.018974287 |
| stats_o/mean       | 0.3003835   |
| stats_o/std        | 0.8264832   |
| test/episode       | 260.0       |
| test/mean_Q        | -3.3167949  |
| test/success_rate  | 0.15        |
| train/episode      | 1300.0      |
| train/success_rate | 0.01        |
------------------------------------
New best success rate: 0.15. Saving policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_best.pkl ...
------------------------------------
| epoch              | 13          |
| stats_g/mean       | 0.6731571   |
| stats_g/std        | 0.018860517 |
| stats_o/mean       | 0.29966283  |
| stats_o/std        | 0.82605207  |
| test/episode       | 280.0       |
| test/mean_Q        | -2.1325078  |
| test/success_rate  | 0.1         |
| train/episode      | 1400.0      |
| train/success_rate | 0.02        |
------------------------------------
------------------------------------
| epoch              | 14          |
| stats_g/mean       | 0.6732932   |
| stats_g/std        | 0.018742811 |
| stats_o/mean       | 0.29986674  |
| stats_o/std        | 0.82653105  |
| test/episode       | 300.0       |
| test/mean_Q        | -5.0721755  |
| test/success_rate  | 0.05        |
| train/episode      | 1500.0      |
| train/success_rate | 0.0         |
------------------------------------
------------------------------------
| epoch              | 15          |
| stats_g/mean       | 0.67336637  |
| stats_g/std        | 0.018713411 |
| stats_o/mean       | 0.29892159  |
| stats_o/std        | 0.8264739   |
| test/episode       | 320.0       |
| test/mean_Q        | -2.7326572  |
| test/success_rate  | 0.15        |
| train/episode      | 1600.0      |
| train/success_rate | 0.01        |
------------------------------------
New best success rate: 0.15. Saving policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_best.pkl ...
Saving periodic policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_15.pkl ...
------------------------------------
| epoch              | 16          |
| stats_g/mean       | 0.6733501   |
| stats_g/std        | 0.018582944 |
| stats_o/mean       | 0.29828107  |
| stats_o/std        | 0.8260105   |
| test/episode       | 340.0       |
| test/mean_Q        | -3.7673676  |
| test/success_rate  | 0.05        |
| train/episode      | 1700.0      |
| train/success_rate | 0.0         |
------------------------------------
------------------------------------
| epoch              | 17          |
| stats_g/mean       | 0.673384    |
| stats_g/std        | 0.018516572 |
| stats_o/mean       | 0.2979001   |
| stats_o/std        | 0.8242809   |
| test/episode       | 360.0       |
| test/mean_Q        | -5.8748794  |
| test/success_rate  | 0.05        |
| train/episode      | 1800.0      |
| train/success_rate | 0.01        |
------------------------------------
------------------------------------
| epoch              | 18          |
| stats_g/mean       | 0.67348033  |
| stats_g/std        | 0.018455824 |
| stats_o/mean       | 0.29823226  |
| stats_o/std        | 0.8236191   |
| test/episode       | 380.0       |
| test/mean_Q        | -7.51431    |
| test/success_rate  | 0.15        |
| train/episode      | 1900.0      |
| train/success_rate | 0.0         |
------------------------------------
New best success rate: 0.15. Saving policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_best.pkl ...
-----------------------------------
| epoch              | 19         |
| stats_g/mean       | 0.67352736 |
| stats_g/std        | 0.01845287 |
| stats_o/mean       | 0.2979018  |
| stats_o/std        | 0.82315314 |
| test/episode       | 400.0      |
| test/mean_Q        | -5.1292343 |
| test/success_rate  | 0.05       |
| train/episode      | 2000.0     |
| train/success_rate | 0.0        |
-----------------------------------
-----------------------------------
| epoch              | 20         |
| stats_g/mean       | 0.6737408  |
| stats_g/std        | 0.01872459 |
| stats_o/mean       | 0.2976037  |
| stats_o/std        | 0.823966   |
| test/episode       | 420.0      |
| test/mean_Q        | -4.7770767 |
| test/success_rate  | 0.2        |
| train/episode      | 2100.0     |
| train/success_rate | 0.0        |
-----------------------------------
New best success rate: 0.2. Saving policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_best.pkl ...
Saving periodic policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_20.pkl ...
------------------------------------
| epoch              | 21          |
| stats_g/mean       | 0.6736794   |
| stats_g/std        | 0.018685045 |
| stats_o/mean       | 0.29734623  |
| stats_o/std        | 0.8247545   |
| test/episode       | 440.0       |
| test/mean_Q        | -3.6801612  |
| test/success_rate  | 0.05        |
| train/episode      | 2200.0      |
| train/success_rate | 0.0         |
------------------------------------
------------------------------------
| epoch              | 22          |
| stats_g/mean       | 0.673701    |
| stats_g/std        | 0.018712554 |
| stats_o/mean       | 0.29752067  |
| stats_o/std        | 0.82489747  |
| test/episode       | 460.0       |
| test/mean_Q        | -6.7992043  |
| test/success_rate  | 0.1         |
| train/episode      | 2300.0      |
| train/success_rate | 0.0         |
------------------------------------
------------------------------------
| epoch              | 23          |
| stats_g/mean       | 0.6737664   |
| stats_g/std        | 0.018699795 |
| stats_o/mean       | 0.29735106  |
| stats_o/std        | 0.82506543  |
| test/episode       | 480.0       |
| test/mean_Q        | -10.155802  |
| test/success_rate  | 0.05        |
| train/episode      | 2400.0      |
| train/success_rate | 0.0         |
------------------------------------
------------------------------------
| epoch              | 24          |
| stats_g/mean       | 0.67378014  |
| stats_g/std        | 0.018663527 |
| stats_o/mean       | 0.29701477  |
| stats_o/std        | 0.8250279   |
| test/episode       | 500.0       |
| test/mean_Q        | -3.6538215  |
| test/success_rate  | 0.1         |
| train/episode      | 2500.0      |
| train/success_rate | 0.0         |
------------------------------------
------------------------------------
| epoch              | 25          |
| stats_g/mean       | 0.6738197   |
| stats_g/std        | 0.018650748 |
| stats_o/mean       | 0.29677483  |
| stats_o/std        | 0.82460207  |
| test/episode       | 520.0       |
| test/mean_Q        | -7.0982575  |
| test/success_rate  | 0.1         |
| train/episode      | 2600.0      |
| train/success_rate | 0.0         |
------------------------------------
Saving periodic policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_25.pkl ...
------------------------------------
| epoch              | 26          |
| stats_g/mean       | 0.6738703   |
| stats_g/std        | 0.018648382 |
| stats_o/mean       | 0.29670042  |
| stats_o/std        | 0.8242242   |
| test/episode       | 540.0       |
| test/mean_Q        | -6.8236594  |
| test/success_rate  | 0.25        |
| train/episode      | 2700.0      |
| train/success_rate | 0.0         |
------------------------------------
New best success rate: 0.25. Saving policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_best.pkl ...
------------------------------------
| epoch              | 27          |
| stats_g/mean       | 0.6738655   |
| stats_g/std        | 0.018600868 |
| stats_o/mean       | 0.296709    |
| stats_o/std        | 0.823976    |
| test/episode       | 560.0       |
| test/mean_Q        | -6.0774617  |
| test/success_rate  | 0.15        |
| train/episode      | 2800.0      |
| train/success_rate | 0.0         |
------------------------------------
------------------------------------
| epoch              | 28          |
| stats_g/mean       | 0.6739022   |
| stats_g/std        | 0.018586172 |
| stats_o/mean       | 0.29687798  |
| stats_o/std        | 0.82415396  |
| test/episode       | 580.0       |
| test/mean_Q        | -8.448231   |
| test/success_rate  | 0.1         |
| train/episode      | 2900.0      |
| train/success_rate | 0.0         |
------------------------------------
-----------------------------------
| epoch              | 29         |
| stats_g/mean       | 0.67394227 |
| stats_g/std        | 0.01856873 |
| stats_o/mean       | 0.2970412  |
| stats_o/std        | 0.82396555 |
| test/episode       | 600.0      |
| test/mean_Q        | -5.0226517 |
| test/success_rate  | 0.1        |
| train/episode      | 3000.0     |
| train/success_rate | 0.01       |
-----------------------------------
------------------------------------
| epoch              | 30          |
| stats_g/mean       | 0.67388237  |
| stats_g/std        | 0.018552434 |
| stats_o/mean       | 0.2971141   |
| stats_o/std        | 0.8234071   |
| test/episode       | 620.0       |
| test/mean_Q        | -9.154192   |
| test/success_rate  | 0.15        |
| train/episode      | 3100.0      |
| train/success_rate | 0.0         |
------------------------------------
Saving periodic policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_30.pkl ...
------------------------------------
| epoch              | 31          |
| stats_g/mean       | 0.673858    |
| stats_g/std        | 0.018508537 |
| stats_o/mean       | 0.2972493   |
| stats_o/std        | 0.82356435  |
| test/episode       | 640.0       |
| test/mean_Q        | -4.3143015  |
| test/success_rate  | 0.15        |
| train/episode      | 3200.0      |
| train/success_rate | 0.02        |
------------------------------------
------------------------------------
| epoch              | 32          |
| stats_g/mean       | 0.67383325  |
| stats_g/std        | 0.018460257 |
| stats_o/mean       | 0.2973487   |
| stats_o/std        | 0.8231163   |
| test/episode       | 660.0       |
| test/mean_Q        | -10.90727   |
| test/success_rate  | 0.1         |
| train/episode      | 3300.0      |
| train/success_rate | 0.02        |
------------------------------------
------------------------------------
| epoch              | 33          |
| stats_g/mean       | 0.6738116   |
| stats_g/std        | 0.018412197 |
| stats_o/mean       | 0.2975577   |
| stats_o/std        | 0.82248765  |
| test/episode       | 680.0       |
| test/mean_Q        | -9.042378   |
| test/success_rate  | 0.25        |
| train/episode      | 3400.0      |
| train/success_rate | 0.0         |
------------------------------------
New best success rate: 0.25. Saving policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_best.pkl ...
------------------------------------
| epoch              | 34          |
| stats_g/mean       | 0.67380756  |
| stats_g/std        | 0.018388245 |
| stats_o/mean       | 0.29754525  |
| stats_o/std        | 0.82252353  |
| test/episode       | 700.0       |
| test/mean_Q        | -11.273317  |
| test/success_rate  | 0.15        |
| train/episode      | 3500.0      |
| train/success_rate | 0.01        |
------------------------------------
------------------------------------
| epoch              | 35          |
| stats_g/mean       | 0.6738022   |
| stats_g/std        | 0.018370472 |
| stats_o/mean       | 0.29770258  |
| stats_o/std        | 0.822192    |
| test/episode       | 720.0       |
| test/mean_Q        | -7.4241843  |
| test/success_rate  | 0.2         |
| train/episode      | 3600.0      |
| train/success_rate | 0.0         |
------------------------------------
Saving periodic policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_35.pkl ...
------------------------------------
| epoch              | 36          |
| stats_g/mean       | 0.67381793  |
| stats_g/std        | 0.018327303 |
| stats_o/mean       | 0.29785573  |
| stats_o/std        | 0.8218368   |
| test/episode       | 740.0       |
| test/mean_Q        | -9.501584   |
| test/success_rate  | 0.15        |
| train/episode      | 3700.0      |
| train/success_rate | 0.0         |
------------------------------------
------------------------------------
| epoch              | 37          |
| stats_g/mean       | 0.6739328   |
| stats_g/std        | 0.018403258 |
| stats_o/mean       | 0.2979958   |
| stats_o/std        | 0.8219744   |
| test/episode       | 760.0       |
| test/mean_Q        | -12.71135   |
| test/success_rate  | 0.1         |
| train/episode      | 3800.0      |
| train/success_rate | 0.0         |
------------------------------------
------------------------------------
| epoch              | 38          |
| stats_g/mean       | 0.67400527  |
| stats_g/std        | 0.018492738 |
| stats_o/mean       | 0.29816893  |
| stats_o/std        | 0.821665    |
| test/episode       | 780.0       |
| test/mean_Q        | -10.15435   |
| test/success_rate  | 0.1         |
| train/episode      | 3900.0      |
| train/success_rate | 0.0         |
------------------------------------
------------------------------------
| epoch              | 39          |
| stats_g/mean       | 0.67420936  |
| stats_g/std        | 0.018759985 |
| stats_o/mean       | 0.2986632   |
| stats_o/std        | 0.8219187   |
| test/episode       | 800.0       |
| test/mean_Q        | -12.094365  |
| test/success_rate  | 0.1         |
| train/episode      | 4000.0      |
| train/success_rate | 0.03        |
------------------------------------
------------------------------------
| epoch              | 40          |
| stats_g/mean       | 0.67436224  |
| stats_g/std        | 0.018902011 |
| stats_o/mean       | 0.2989876   |
| stats_o/std        | 0.82187045  |
| test/episode       | 820.0       |
| test/mean_Q        | -7.031053   |
| test/success_rate  | 0.2         |
| train/episode      | 4100.0      |
| train/success_rate | 0.01        |
------------------------------------
Saving periodic policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_40.pkl ...
------------------------------------
| epoch              | 41          |
| stats_g/mean       | 0.6744231   |
| stats_g/std        | 0.018963275 |
| stats_o/mean       | 0.29913667  |
| stats_o/std        | 0.82145476  |
| test/episode       | 840.0       |
| test/mean_Q        | -11.192993  |
| test/success_rate  | 0.0         |
| train/episode      | 4200.0      |
| train/success_rate | 0.0         |
------------------------------------
------------------------------------
| epoch              | 42          |
| stats_g/mean       | 0.67439693  |
| stats_g/std        | 0.019077377 |
| stats_o/mean       | 0.29959014  |
| stats_o/std        | 0.82159275  |
| test/episode       | 860.0       |
| test/mean_Q        | -5.4379206  |
| test/success_rate  | 0.1         |
| train/episode      | 4300.0      |
| train/success_rate | 0.0         |
------------------------------------
------------------------------------
| epoch              | 43          |
| stats_g/mean       | 0.67438227  |
| stats_g/std        | 0.019058831 |
| stats_o/mean       | 0.29950958  |
| stats_o/std        | 0.8215844   |
| test/episode       | 880.0       |
| test/mean_Q        | -14.859442  |
| test/success_rate  | 0.1         |
| train/episode      | 4400.0      |
| train/success_rate | 0.0         |
------------------------------------
-----------------------------------
| epoch              | 44         |
| stats_g/mean       | 0.6743811  |
| stats_g/std        | 0.01904079 |
| stats_o/mean       | 0.29949787 |
| stats_o/std        | 0.82165277 |
| test/episode       | 900.0      |
| test/mean_Q        | -5.924157  |
| test/success_rate  | 0.15       |
| train/episode      | 4500.0     |
| train/success_rate | 0.0        |
-----------------------------------
-----------------------------------
| epoch              | 45         |
| stats_g/mean       | 0.67440134 |
| stats_g/std        | 0.01906165 |
| stats_o/mean       | 0.2993586  |
| stats_o/std        | 0.8215495  |
| test/episode       | 920.0      |
| test/mean_Q        | -9.628291  |
| test/success_rate  | 0.0        |
| train/episode      | 4600.0     |
| train/success_rate | 0.01       |
-----------------------------------
Saving periodic policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_45.pkl ...
------------------------------------
| epoch              | 46          |
| stats_g/mean       | 0.67441565  |
| stats_g/std        | 0.019056907 |
| stats_o/mean       | 0.2992346   |
| stats_o/std        | 0.8212169   |
| test/episode       | 940.0       |
| test/mean_Q        | -11.904111  |
| test/success_rate  | 0.15        |
| train/episode      | 4700.0      |
| train/success_rate | 0.01        |
------------------------------------
------------------------------------
| epoch              | 47          |
| stats_g/mean       | 0.67443377  |
| stats_g/std        | 0.019026894 |
| stats_o/mean       | 0.29926038  |
| stats_o/std        | 0.82080775  |
| test/episode       | 960.0       |
| test/mean_Q        | -12.621243  |
| test/success_rate  | 0.25        |
| train/episode      | 4800.0      |
| train/success_rate | 0.01        |
------------------------------------
New best success rate: 0.25. Saving policy to HandReach-v0/cpu1ep50buffer1E5/alg=DDPG+CHER=/r0/policy_best.pkl ...
------------------------------------
| epoch              | 48          |
| stats_g/mean       | 0.6744273   |
| stats_g/std        | 0.018995358 |
| stats_o/mean       | 0.299289    |
| stats_o/std        | 0.82032144  |
| test/episode       | 980.0       |
| test/mean_Q        | -9.796079   |
| test/success_rate  | 0.1         |
| train/episode      | 4900.0      |
| train/success_rate | 0.0         |
------------------------------------
------------------------------------
| epoch              | 49          |
| stats_g/mean       | 0.6744276   |
| stats_g/std        | 0.018969228 |
| stats_o/mean       | 0.29932165  |
| stats_o/std        | 0.8197719   |
| test/episode       | 1000.0      |
| test/mean_Q        | -10.628295  |
| test/success_rate  | 0.05        |
| train/episode      | 5000.0      |
| train/success_rate | 0.0         |
------------------------------------
