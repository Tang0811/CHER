Logging to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2
T: 50
_Q_lr: 0.001
_action_l2: 1.0
_batch_size: 64
_buffer_size: 1000000
_clip_obs: 200.0
_hidden: 256
_layers: 3
_max_u: 1.0
_network_class: baselines.her.actor_critic:ActorCritic
_norm_clip: 5
_norm_eps: 0.01
_pi_lr: 0.001
_polyak: 0.95
_relative_goals: False
_scope: ddpg
ddpg_params: {'polyak': 0.95, 'buffer_size': 1000000, 'batch_size': 64, 'clip_obs': 200.0, 'network_class': 'baselines.her.actor_critic:ActorCritic', 'action_l2': 1.0, 'hidden': 256, 'layers': 3, 'Q_lr': 0.001, 'relative_goals': False, 'pi_lr': 0.001, 'max_u': 1.0, 'scope': 'ddpg', 'norm_clip': 5, 'norm_eps': 0.01}
env_name: HandReach-v0
gamma: 0.98
make_env: <function prepare_params.<locals>.make_env at 0x7f5139bb6bf8>
n_batches: 40
n_cycles: 50
n_test_rollouts: 10
noise_eps: 0.2
random_eps: 0.3
replay_k: 4
replay_strategy: future
rollout_batch_size: 2
test_with_polyak: False
Creating a DDPG agent with action space 20 x 1.0...
Training...
------------------------------------
| epoch              | 0           |
| stats_g/mean       | 0.6724971   |
| stats_g/std        | 0.019046042 |
| stats_o/mean       | 0.30991006  |
| stats_o/std        | 0.706813    |
| test/episode       | 20.0        |
| test/mean_Q        | -2.446558   |
| test/success_rate  | 0.0         |
| train/episode      | 100.0       |
| train/success_rate | 0.0         |
------------------------------------
New best success rate: 0.0. Saving policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_best.pkl ...
Saving periodic policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_0.pkl ...
------------------------------------
| epoch              | 1           |
| stats_g/mean       | 0.67454445  |
| stats_g/std        | 0.019371875 |
| stats_o/mean       | 0.3071056   |
| stats_o/std        | 0.7504107   |
| test/episode       | 40.0        |
| test/mean_Q        | -2.4850678  |
| test/success_rate  | 0.0         |
| train/episode      | 200.0       |
| train/success_rate | 0.0         |
------------------------------------
New best success rate: 0.0. Saving policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_best.pkl ...
------------------------------------
| epoch              | 2           |
| stats_g/mean       | 0.6746906   |
| stats_g/std        | 0.018997323 |
| stats_o/mean       | 0.30639857  |
| stats_o/std        | 0.7793367   |
| test/episode       | 60.0        |
| test/mean_Q        | -2.188768   |
| test/success_rate  | 0.0         |
| train/episode      | 300.0       |
| train/success_rate | 0.0         |
------------------------------------
New best success rate: 0.0. Saving policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_best.pkl ...
------------------------------------
| epoch              | 3           |
| stats_g/mean       | 0.6746624   |
| stats_g/std        | 0.018690413 |
| stats_o/mean       | 0.3068493   |
| stats_o/std        | 0.7940342   |
| test/episode       | 80.0        |
| test/mean_Q        | -2.9943967  |
| test/success_rate  | 0.0         |
| train/episode      | 400.0       |
| train/success_rate | 0.002       |
------------------------------------
New best success rate: 0.0. Saving policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_best.pkl ...
------------------------------------
| epoch              | 4           |
| stats_g/mean       | 0.6748115   |
| stats_g/std        | 0.018464882 |
| stats_o/mean       | 0.30766976  |
| stats_o/std        | 0.8022417   |
| test/episode       | 100.0       |
| test/mean_Q        | -3.1455135  |
| test/success_rate  | 0.15        |
| train/episode      | 500.0       |
| train/success_rate | 0.005       |
------------------------------------
New best success rate: 0.15. Saving policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_best.pkl ...
--------------------------------------------
| epoch              | 5                   |
| stats_g/mean       | 0.6749856           |
| stats_g/std        | 0.018452665         |
| stats_o/mean       | 0.30843106          |
| stats_o/std        | 0.8089798           |
| test/episode       | 120.0               |
| test/mean_Q        | -3.397585           |
| test/success_rate  | 0.11500000000000002 |
| train/episode      | 600.0               |
| train/success_rate | 0.005               |
--------------------------------------------
Saving periodic policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_5.pkl ...
------------------------------------
| epoch              | 6           |
| stats_g/mean       | 0.6749667   |
| stats_g/std        | 0.018262599 |
| stats_o/mean       | 0.30883032  |
| stats_o/std        | 0.81279516  |
| test/episode       | 140.0       |
| test/mean_Q        | -3.742022   |
| test/success_rate  | 0.2         |
| train/episode      | 700.0       |
| train/success_rate | 0.005       |
------------------------------------
New best success rate: 0.2. Saving policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_best.pkl ...
-----------------------------------
| epoch              | 7          |
| stats_g/mean       | 0.67498815 |
| stats_g/std        | 0.01811194 |
| stats_o/mean       | 0.30927572 |
| stats_o/std        | 0.8132057  |
| test/episode       | 160.0      |
| test/mean_Q        | -5.156232  |
| test/success_rate  | 0.195      |
| train/episode      | 800.0      |
| train/success_rate | 0.006      |
-----------------------------------
------------------------------------
| epoch              | 8           |
| stats_g/mean       | 0.6750393   |
| stats_g/std        | 0.018027494 |
| stats_o/mean       | 0.30954444  |
| stats_o/std        | 0.81346416  |
| test/episode       | 180.0       |
| test/mean_Q        | -4.455649   |
| test/success_rate  | 0.185       |
| train/episode      | 900.0       |
| train/success_rate | 0.006       |
------------------------------------
--------------------------------------------
| epoch              | 9                   |
| stats_g/mean       | 0.6750729           |
| stats_g/std        | 0.017960599         |
| stats_o/mean       | 0.30962998          |
| stats_o/std        | 0.81362915          |
| test/episode       | 200.0               |
| test/mean_Q        | -4.581128           |
| test/success_rate  | 0.09000000000000001 |
| train/episode      | 1000.0              |
| train/success_rate | 0.01                |
--------------------------------------------
--------------------------------------------
| epoch              | 10                  |
| stats_g/mean       | 0.6751262           |
| stats_g/std        | 0.017905682         |
| stats_o/mean       | 0.30966097          |
| stats_o/std        | 0.8134912           |
| test/episode       | 220.0               |
| test/mean_Q        | -5.5229826          |
| test/success_rate  | 0.12000000000000002 |
| train/episode      | 1100.0              |
| train/success_rate | 0.004               |
--------------------------------------------
Saving periodic policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_10.pkl ...
-----------------------------------
| epoch              | 11         |
| stats_g/mean       | 0.6751501  |
| stats_g/std        | 0.01786686 |
| stats_o/mean       | 0.3096117  |
| stats_o/std        | 0.8133276  |
| test/episode       | 240.0      |
| test/mean_Q        | -5.4335346 |
| test/success_rate  | 0.1        |
| train/episode      | 1200.0     |
| train/success_rate | 0.012      |
-----------------------------------
--------------------------------------------
| epoch              | 12                  |
| stats_g/mean       | 0.6751932           |
| stats_g/std        | 0.017855579         |
| stats_o/mean       | 0.30971083          |
| stats_o/std        | 0.81277925          |
| test/episode       | 260.0               |
| test/mean_Q        | -5.990133           |
| test/success_rate  | 0.27999999999999997 |
| train/episode      | 1300.0              |
| train/success_rate | 0.005               |
--------------------------------------------
New best success rate: 0.27999999999999997. Saving policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_best.pkl ...
------------------------------------
| epoch              | 13          |
| stats_g/mean       | 0.6752571   |
| stats_g/std        | 0.017852705 |
| stats_o/mean       | 0.30973047  |
| stats_o/std        | 0.8123458   |
| test/episode       | 280.0       |
| test/mean_Q        | -4.935382   |
| test/success_rate  | 0.33        |
| train/episode      | 1400.0      |
| train/success_rate | 0.006       |
------------------------------------
New best success rate: 0.33. Saving policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_best.pkl ...
---------------------------------------------
| epoch              | 14                   |
| stats_g/mean       | 0.6752986            |
| stats_g/std        | 0.01783219           |
| stats_o/mean       | 0.30973196           |
| stats_o/std        | 0.81208265           |
| test/episode       | 300.0                |
| test/mean_Q        | -6.7647414           |
| test/success_rate  | 0.255                |
| train/episode      | 1500.0               |
| train/success_rate | 0.009000000000000001 |
---------------------------------------------
---------------------------------------------
| epoch              | 15                   |
| stats_g/mean       | 0.6752986            |
| stats_g/std        | 0.017799255          |
| stats_o/mean       | 0.30983764           |
| stats_o/std        | 0.81166804           |
| test/episode       | 320.0                |
| test/mean_Q        | -7.334111            |
| test/success_rate  | 0.22999999999999998  |
| train/episode      | 1600.0               |
| train/success_rate | 0.011000000000000001 |
---------------------------------------------
Saving periodic policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_15.pkl ...
---------------------------------------------
| epoch              | 16                   |
| stats_g/mean       | 0.6752833            |
| stats_g/std        | 0.01777359           |
| stats_o/mean       | 0.30995208           |
| stats_o/std        | 0.81131345           |
| test/episode       | 340.0                |
| test/mean_Q        | -7.0213294           |
| test/success_rate  | 0.41500000000000004  |
| train/episode      | 1700.0               |
| train/success_rate | 0.007000000000000001 |
---------------------------------------------
New best success rate: 0.41500000000000004. Saving policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_best.pkl ...
------------------------------------
| epoch              | 17          |
| stats_g/mean       | 0.6752926   |
| stats_g/std        | 0.017768886 |
| stats_o/mean       | 0.3101162   |
| stats_o/std        | 0.8111266   |
| test/episode       | 360.0       |
| test/mean_Q        | -8.629865   |
| test/success_rate  | 0.39        |
| train/episode      | 1800.0      |
| train/success_rate | 0.009       |
------------------------------------
---------------------------------------------
| epoch              | 18                   |
| stats_g/mean       | 0.67531264           |
| stats_g/std        | 0.017789613          |
| stats_o/mean       | 0.3103345            |
| stats_o/std        | 0.8111739            |
| test/episode       | 380.0                |
| test/mean_Q        | -7.222722            |
| test/success_rate  | 0.49499999999999994  |
| train/episode      | 1900.0               |
| train/success_rate | 0.007000000000000001 |
---------------------------------------------
New best success rate: 0.49499999999999994. Saving policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_best.pkl ...
---------------------------------------------
| epoch              | 19                   |
| stats_g/mean       | 0.67531073           |
| stats_g/std        | 0.017804485          |
| stats_o/mean       | 0.31050754           |
| stats_o/std        | 0.81121767           |
| test/episode       | 400.0                |
| test/mean_Q        | -8.50647             |
| test/success_rate  | 0.41500000000000004  |
| train/episode      | 2000.0               |
| train/success_rate | 0.014000000000000002 |
---------------------------------------------
------------------------------------
| epoch              | 20          |
| stats_g/mean       | 0.67531264  |
| stats_g/std        | 0.017783564 |
| stats_o/mean       | 0.31059068  |
| stats_o/std        | 0.8108761   |
| test/episode       | 420.0       |
| test/mean_Q        | -8.962689   |
| test/success_rate  | 0.375       |
| train/episode      | 2100.0      |
| train/success_rate | 0.012       |
------------------------------------
Saving periodic policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_20.pkl ...
------------------------------------
| epoch              | 21          |
| stats_g/mean       | 0.6753098   |
| stats_g/std        | 0.017758973 |
| stats_o/mean       | 0.31057018  |
| stats_o/std        | 0.8105677   |
| test/episode       | 440.0       |
| test/mean_Q        | -8.957021   |
| test/success_rate  | 0.4         |
| train/episode      | 2200.0      |
| train/success_rate | 0.012       |
------------------------------------
---------------------------------------------
| epoch              | 22                   |
| stats_g/mean       | 0.67530644           |
| stats_g/std        | 0.01773884           |
| stats_o/mean       | 0.31054336           |
| stats_o/std        | 0.81021565           |
| test/episode       | 460.0                |
| test/mean_Q        | -7.8613524           |
| test/success_rate  | 0.485                |
| train/episode      | 2300.0               |
| train/success_rate | 0.014000000000000002 |
---------------------------------------------
-------------------------------------------
| epoch              | 23                 |
| stats_g/mean       | 0.6753051          |
| stats_g/std        | 0.01771314         |
| stats_o/mean       | 0.31047863         |
| stats_o/std        | 0.8101738          |
| test/episode       | 480.0              |
| test/mean_Q        | -10.382485         |
| test/success_rate  | 0.5650000000000001 |
| train/episode      | 2400.0             |
| train/success_rate | 0.018              |
-------------------------------------------
New best success rate: 0.5650000000000001. Saving policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_best.pkl ...
---------------------------------------------
| epoch              | 24                   |
| stats_g/mean       | 0.6753057            |
| stats_g/std        | 0.017693454          |
| stats_o/mean       | 0.31034222           |
| stats_o/std        | 0.8099572            |
| test/episode       | 500.0                |
| test/mean_Q        | -6.5740914           |
| test/success_rate  | 0.7050000000000001   |
| train/episode      | 2500.0               |
| train/success_rate | 0.014000000000000002 |
---------------------------------------------
New best success rate: 0.7050000000000001. Saving policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_best.pkl ...
------------------------------------
| epoch              | 25          |
| stats_g/mean       | 0.67528856  |
| stats_g/std        | 0.017668119 |
| stats_o/mean       | 0.31030256  |
| stats_o/std        | 0.8096148   |
| test/episode       | 520.0       |
| test/mean_Q        | -9.3285055  |
| test/success_rate  | 0.575       |
| train/episode      | 2600.0      |
| train/success_rate | 0.011       |
------------------------------------
Saving periodic policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_25.pkl ...
------------------------------------
| epoch              | 26          |
| stats_g/mean       | 0.6752809   |
| stats_g/std        | 0.017644634 |
| stats_o/mean       | 0.3101627   |
| stats_o/std        | 0.8093295   |
| test/episode       | 540.0       |
| test/mean_Q        | -8.920512   |
| test/success_rate  | 0.72        |
| train/episode      | 2700.0      |
| train/success_rate | 0.011       |
------------------------------------
New best success rate: 0.72. Saving policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_best.pkl ...
--------------------------------------------
| epoch              | 27                  |
| stats_g/mean       | 0.6752737           |
| stats_g/std        | 0.01763093          |
| stats_o/mean       | 0.31004488          |
| stats_o/std        | 0.8093007           |
| test/episode       | 560.0               |
| test/mean_Q        | -11.766255          |
| test/success_rate  | 0.45500000000000007 |
| train/episode      | 2800.0              |
| train/success_rate | 0.018               |
--------------------------------------------
---------------------------------------------
| epoch              | 28                   |
| stats_g/mean       | 0.6752784            |
| stats_g/std        | 0.017617349          |
| stats_o/mean       | 0.30999565           |
| stats_o/std        | 0.80894977           |
| test/episode       | 580.0                |
| test/mean_Q        | -11.117389           |
| test/success_rate  | 0.6                  |
| train/episode      | 2900.0               |
| train/success_rate | 0.014000000000000002 |
---------------------------------------------
---------------------------------------------
| epoch              | 29                   |
| stats_g/mean       | 0.67527366           |
| stats_g/std        | 0.017603908          |
| stats_o/mean       | 0.30999598           |
| stats_o/std        | 0.80856884           |
| test/episode       | 600.0                |
| test/mean_Q        | -10.361181           |
| test/success_rate  | 0.5650000000000001   |
| train/episode      | 3000.0               |
| train/success_rate | 0.013000000000000001 |
---------------------------------------------
---------------------------------------------
| epoch              | 30                   |
| stats_g/mean       | 0.6752709            |
| stats_g/std        | 0.01759615           |
| stats_o/mean       | 0.30996257           |
| stats_o/std        | 0.8083603            |
| test/episode       | 620.0                |
| test/mean_Q        | -9.467162            |
| test/success_rate  | 0.655                |
| train/episode      | 3100.0               |
| train/success_rate | 0.006999999999999999 |
---------------------------------------------
Saving periodic policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_30.pkl ...
------------------------------------
| epoch              | 31          |
| stats_g/mean       | 0.6752794   |
| stats_g/std        | 0.01759265  |
| stats_o/mean       | 0.30989566  |
| stats_o/std        | 0.8083197   |
| test/episode       | 640.0       |
| test/mean_Q        | -11.5301075 |
| test/success_rate  | 0.62        |
| train/episode      | 3200.0      |
| train/success_rate | 0.016       |
------------------------------------
------------------------------------
| epoch              | 32          |
| stats_g/mean       | 0.6752746   |
| stats_g/std        | 0.017582979 |
| stats_o/mean       | 0.3098846   |
| stats_o/std        | 0.808046    |
| test/episode       | 660.0       |
| test/mean_Q        | -11.616719  |
| test/success_rate  | 0.62        |
| train/episode      | 3300.0      |
| train/success_rate | 0.01        |
------------------------------------
---------------------------------------------
| epoch              | 33                   |
| stats_g/mean       | 0.67526186           |
| stats_g/std        | 0.017570863          |
| stats_o/mean       | 0.30982834           |
| stats_o/std        | 0.80791223           |
| test/episode       | 680.0                |
| test/mean_Q        | -11.146794           |
| test/success_rate  | 0.5                  |
| train/episode      | 3400.0               |
| train/success_rate | 0.011000000000000001 |
---------------------------------------------
---------------------------------------------
| epoch              | 34                   |
| stats_g/mean       | 0.6752628            |
| stats_g/std        | 0.01756851           |
| stats_o/mean       | 0.309774             |
| stats_o/std        | 0.80782044           |
| test/episode       | 700.0                |
| test/mean_Q        | -11.283148           |
| test/success_rate  | 0.605                |
| train/episode      | 3500.0               |
| train/success_rate | 0.013000000000000001 |
---------------------------------------------
------------------------------------
| epoch              | 35          |
| stats_g/mean       | 0.67525876  |
| stats_g/std        | 0.017569015 |
| stats_o/mean       | 0.30972725  |
| stats_o/std        | 0.80746937  |
| test/episode       | 720.0       |
| test/mean_Q        | -14.182963  |
| test/success_rate  | 0.575       |
| train/episode      | 3600.0      |
| train/success_rate | 0.01        |
------------------------------------
Saving periodic policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_35.pkl ...
-------------------------------------------
| epoch              | 36                 |
| stats_g/mean       | 0.67525387         |
| stats_g/std        | 0.017566884        |
| stats_o/mean       | 0.30970109         |
| stats_o/std        | 0.8072346          |
| test/episode       | 740.0              |
| test/mean_Q        | -13.161308         |
| test/success_rate  | 0.5900000000000001 |
| train/episode      | 3700.0             |
| train/success_rate | 0.01               |
-------------------------------------------
---------------------------------------------
| epoch              | 37                   |
| stats_g/mean       | 0.675247             |
| stats_g/std        | 0.017563364          |
| stats_o/mean       | 0.30962816           |
| stats_o/std        | 0.80702245           |
| test/episode       | 760.0                |
| test/mean_Q        | -12.382299           |
| test/success_rate  | 0.525                |
| train/episode      | 3800.0               |
| train/success_rate | 0.013000000000000001 |
---------------------------------------------
-------------------------------------------
| epoch              | 38                 |
| stats_g/mean       | 0.675247           |
| stats_g/std        | 0.017566819        |
| stats_o/mean       | 0.30956593         |
| stats_o/std        | 0.8069785          |
| test/episode       | 780.0              |
| test/mean_Q        | -12.971349         |
| test/success_rate  | 0.5800000000000001 |
| train/episode      | 3900.0             |
| train/success_rate | 0.009              |
-------------------------------------------
------------------------------------
| epoch              | 39          |
| stats_g/mean       | 0.6752428   |
| stats_g/std        | 0.017567497 |
| stats_o/mean       | 0.3094903   |
| stats_o/std        | 0.80686647  |
| test/episode       | 800.0       |
| test/mean_Q        | -14.2091675 |
| test/success_rate  | 0.54        |
| train/episode      | 4000.0      |
| train/success_rate | 0.011       |
------------------------------------
---------------------------------------------
| epoch              | 40                   |
| stats_g/mean       | 0.67523766           |
| stats_g/std        | 0.017563768          |
| stats_o/mean       | 0.30945253           |
| stats_o/std        | 0.8066201            |
| test/episode       | 820.0                |
| test/mean_Q        | -12.297045           |
| test/success_rate  | 0.6799999999999999   |
| train/episode      | 4100.0               |
| train/success_rate | 0.013000000000000001 |
---------------------------------------------
Saving periodic policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_40.pkl ...
---------------------------------------------
| epoch              | 41                   |
| stats_g/mean       | 0.67522776           |
| stats_g/std        | 0.017553842          |
| stats_o/mean       | 0.30944455           |
| stats_o/std        | 0.8064458            |
| test/episode       | 840.0                |
| test/mean_Q        | -15.347403           |
| test/success_rate  | 0.605                |
| train/episode      | 4200.0               |
| train/success_rate | 0.014000000000000002 |
---------------------------------------------
------------------------------------
| epoch              | 42          |
| stats_g/mean       | 0.6752325   |
| stats_g/std        | 0.017547786 |
| stats_o/mean       | 0.30941623  |
| stats_o/std        | 0.8061539   |
| test/episode       | 860.0       |
| test/mean_Q        | -12.047304  |
| test/success_rate  | 0.665       |
| train/episode      | 4300.0      |
| train/success_rate | 0.005       |
------------------------------------
---------------------------------------------
| epoch              | 43                   |
| stats_g/mean       | 0.6752337            |
| stats_g/std        | 0.017534634          |
| stats_o/mean       | 0.30931693           |
| stats_o/std        | 0.80592316           |
| test/episode       | 880.0                |
| test/mean_Q        | -14.9804945          |
| test/success_rate  | 0.64                 |
| train/episode      | 4400.0               |
| train/success_rate | 0.013000000000000001 |
---------------------------------------------
-------------------------------------------
| epoch              | 44                 |
| stats_g/mean       | 0.6752366          |
| stats_g/std        | 0.017529842        |
| stats_o/mean       | 0.30923444         |
| stats_o/std        | 0.8055641          |
| test/episode       | 900.0              |
| test/mean_Q        | -14.319626         |
| test/success_rate  | 0.5900000000000001 |
| train/episode      | 4500.0             |
| train/success_rate | 0.012              |
-------------------------------------------
------------------------------------
| epoch              | 45          |
| stats_g/mean       | 0.6752366   |
| stats_g/std        | 0.017523922 |
| stats_o/mean       | 0.30919725  |
| stats_o/std        | 0.80532724  |
| test/episode       | 920.0       |
| test/mean_Q        | -13.272433  |
| test/success_rate  | 0.62        |
| train/episode      | 4600.0      |
| train/success_rate | 0.012       |
------------------------------------
Saving periodic policy to HandReach-v0/cpu1ep50/alg=DDPG+HER=/r2/policy_45.pkl ...
------------------------------------
| epoch              | 46          |
| stats_g/mean       | 0.6752421   |
| stats_g/std        | 0.017523054 |
| stats_o/mean       | 0.30916935  |
| stats_o/std        | 0.8051114   |
| test/episode       | 940.0       |
| test/mean_Q        | -14.53723   |
| test/success_rate  | 0.63        |
| train/episode      | 4700.0      |
| train/success_rate | 0.012       |
------------------------------------
------------------------------------
| epoch              | 47          |
| stats_g/mean       | 0.67523134  |
| stats_g/std        | 0.017516281 |
| stats_o/mean       | 0.3091238   |
| stats_o/std        | 0.80491763  |
| test/episode       | 960.0       |
| test/mean_Q        | -13.417928  |
| test/success_rate  | 0.615       |
| train/episode      | 4800.0      |
| train/success_rate | 0.011       |
------------------------------------
-------------------------------------------
| epoch              | 48                 |
| stats_g/mean       | 0.67522895         |
| stats_g/std        | 0.017517563        |
| stats_o/mean       | 0.30910653         |
| stats_o/std        | 0.80473626         |
| test/episode       | 980.0              |
| test/mean_Q        | -13.318636         |
| test/success_rate  | 0.6699999999999999 |
| train/episode      | 4900.0             |
| train/success_rate | 0.01               |
-------------------------------------------
---------------------------------------------
| epoch              | 49                   |
| stats_g/mean       | 0.6752278            |
| stats_g/std        | 0.017516691          |
| stats_o/mean       | 0.30907542           |
| stats_o/std        | 0.8045372            |
| test/episode       | 1000.0               |
| test/mean_Q        | -15.533442           |
| test/success_rate  | 0.5700000000000001   |
| train/episode      | 5000.0               |
| train/success_rate | 0.013000000000000001 |
---------------------------------------------
